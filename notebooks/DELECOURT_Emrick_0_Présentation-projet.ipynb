{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; color: #1E90FF; font-weight: bold; text-transform: uppercase; text-decoration: underline; text-decoration-color: red; background-color: black; padding: 10px;\">\n",
    "        Réalisez une analyse de sentiments grâce au Deep Learning\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\" color: black; font-weight: bold; background-color: #f9e79f; padding: 10px; border-radius: 5px;\">\n",
    "    Description du projet :\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le projet consiste à développer un système d'intelligence artificielle capable d'analyser et de prédire le sentiment exprimé dans des tweets en lien avec la compagnie aérienne \"Air Paradis\". Ce système vise à identifier rapidement les tweets négatifs pour permettre à l'entreprise d'anticiper d'éventuels bad buzz et d'améliorer sa réputation en ligne. \n",
    "\n",
    "Pour ce faire, un prototype de modèle de Deep Learning sera développé en exploitant des données open-source, telles que le jeu de données Sentiment140, qui contient des tweets étiquetés selon leur tonalité (positive ou négative). Le modèle sera ensuite déployé sous forme d'une API sur une plateforme Cloud, permettant d'interagir avec le système en soumettant des tweets et en recevant une prédiction de sentiment en temps réel.\n",
    "\n",
    "Le projet s'articule autour de plusieurs étapes clés : la collecte et le prétraitement des données, l'entraînement et l'évaluation de divers modèles de machine learning et deep learning, l'intégration des pratiques MLOps pour la gestion des expérimentations, et enfin le déploiement du modèle sous forme d'une API accessible à partir d'une interface utilisateur locale, via un notebook ou une application Streamlit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\" color: black; font-weight: bold; background-color: #f9e79f; padding: 10px; border-radius: 5px;\">\n",
    "    Problématique :\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment prédire avec précision le sentiment des tweets sans données clients internes, en utilisant des données open-source et en intégrant les principes MLOps pour assurer un suivi et une amélioration continue du modèle ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\" color: black; font-weight: bold; background-color: #f9e79f; padding: 10px; border-radius: 5px;\">\n",
    "    Objectifs du projet :\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Développer plusieurs approches de modélisation** :\n",
    "  - Approche classique (régression logistique, par exemple).\n",
    "  - Approche avancée avec réseaux de neurones profonds (CNN/LSTM).\n",
    "  - Approche basée sur le modèle BERT.\n",
    "- **Déployer une API Cloud** permettant l'accès au modèle.\n",
    "- **Intégrer la gestion des expérimentations** via MLFlow.\n",
    "- **Mettre en œuvre un pipeline CI/CD** pour le déploiement continu.\n",
    "- **Surveiller les performances en production** grâce à Azure Application Insight.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\" color: black; font-weight: bold; background-color: #f9e79f; padding: 10px; border-radius: 5px;\">\n",
    "    Défis techniques :\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecte et prétraitement des données.\n",
    "- Comparaison des performances entre différentes approches.\n",
    "- Déploiement sur des services Cloud gratuits.\n",
    "- Suivi des performances et amélioration continue du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\" color: black; font-weight: bold; background-color: #f9e79f; padding: 10px; border-radius: 5px;\">\n",
    "    Résultat attendu :\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **API de prédiction opérationnelle**, accessible sur le Cloud.\n",
    "- **Scripts de modélisation complets**, incluant le tracking des expérimentations.\n",
    "- **Interface de test interactive**, permettant la saisie et validation des prédictions.\n",
    "- **Article de blog détaillé**, expliquant les choix techniques et la démarche MLOps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\" color: black; font-weight: bold; background-color: #f9e79f; padding: 10px; border-radius: 5px;\">\n",
    "    Méthodologie et structure par livrable :\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Livrable 1 : Lien API**\n",
    "  - **Demande :** Déployer l'API de prédiction du score, qui expose le “Modèle sur mesure avancé”, sur un service Cloud et fournir le lien d'accès.\n",
    "  - **Étapes :**\n",
    "    1. Développer une API Flask/FastAPI.\n",
    "    2. Déployer l'API sur une plateforme Cloud (Azure, AWS, Heroku).\n",
    "    3. Tester l'API avec des requêtes POST.\n",
    "    4. Documenter l'API dans un fichier README.\n",
    "  - **Source :** Un document bloc-note contenant le lien vers l'API sur le Cloud.\n",
    "\n",
    "- **Livrable 2 : Scripts de modélisation**\n",
    "  - **Demande :** Fournir trois scripts Python pour les approches classique, sur mesure avancé et BERT, incluant la gestion des expérimentations avec MLFlow.\n",
    "  - **Étapes :**\n",
    "    1. Implémenter la régression logistique pour l'approche classique.\n",
    "    2. Développer un modèle de deep learning avec TensorFlow/Keras.\n",
    "    3. Intégrer BERT pour l'approche avancée.\n",
    "    4. Utiliser MLFlow pour le suivi des expérimentations.\n",
    "  - **Source :** Répertoire GitHub contenant les scripts Python organisés par approche.\n",
    "\n",
    "- **Livrable 3 : Dossier de code versionné**\n",
    "  - **Demande :** Structurer et documenter les notebooks comprenant l'EDA, le feature engineering et la modélisation.\n",
    "  - **Étapes :**\n",
    "    1. Réaliser une analyse exploratoire des données (EDA).\n",
    "    2. Effectuer l'ingénierie des caractéristiques (feature engineering).\n",
    "    3. Implémenter les trois approches de modélisation.\n",
    "    4. Rédiger un README détaillé expliquant le code et l'organisation des fichiers.\n",
    "  - **Source :** Dépôt GitHub structuré avec documentation complète et explicative.\n",
    "\n",
    "- **Livrable 4 : Interface de test de l’API**\n",
    "  - **Demande :** Développer une interface locale permettant la saisie d'un tweet et l'affichage de la prédiction.\n",
    "  - **Étapes :**\n",
    "    1. Développer une application Streamlit ou un notebook interactif.\n",
    "    2. Permettre la saisie d’un tweet et l'affichage du sentiment.\n",
    "    3. Intégrer la validation utilisateur et l'envoi des traces à Azure Application Insight.\n",
    "  - **Source :** Application locale exécutée sur l’ordinateur.\n",
    "\n",
    "- **Livrable 5 : Article de blog**\n",
    "  - **Demande :** Rédiger un article détaillé sur la comparaison des modèles et la démarche MLOps.\n",
    "  - **Étapes :**\n",
    "    1. Décrire les trois approches de modélisation.\n",
    "    2. Présenter la démarche MLOps appliquée.\n",
    "    3. Inclure des graphiques et visualisations des résultats.\n",
    "  - **Source :** Document texte avec captures d’écran des résultats.\n",
    "\n",
    "- **Livrable 6 : Support de présentation**\n",
    "  - **Demande :** Préparer une présentation PowerPoint expliquant la démarche méthodologique, les résultats et la mise en production du modèle.\n",
    "  - **Étapes :**\n",
    "    1. Expliquer la démarche méthodologique.\n",
    "    2. Présenter les résultats obtenus.\n",
    "    3. Détailler le processus de mise en production.\n",
    "  - **Source :** Fichier PPT préparé pour la soutenance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\" color: black; font-weight: bold; background-color: #f9e79f; padding: 10px; border-radius: 5px;\">\n",
    "    Points de vigilance :\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Déploiement Cloud :**\n",
    "  - Vérifier la compatibilité avec les services Cloud gratuits (Azure WebApp, AWS, Heroku Student Pack).\n",
    "  - Assurer une configuration sécurisée des endpoints API pour éviter les accès non autorisés.\n",
    "  - Surveiller la latence de l'API et prévoir des optimisations pour garantir un temps de réponse acceptable.\n",
    "\n",
    "- **Gestion des expérimentations :**\n",
    "  - Assurer l’enregistrement systématique des hyperparamètres et des métriques de performance.\n",
    "  - Comparer les performances entre les différentes approches (modèle classique, avancé, BERT).\n",
    "  - Effectuer des sauvegardes régulières des modèles entraînés pour garantir la reproductibilité.\n",
    "\n",
    "- **Structure du code :**\n",
    "  - Organiser le dépôt GitHub en sections distinctes : data, models, scripts, notebooks.\n",
    "  - Ajouter des tests unitaires pour chaque composant critique du projet.\n",
    "  - Documenter le flux de travail et les dépendances dans un fichier README clair et détaillé.\n",
    "\n",
    "- **Interface utilisateur :**\n",
    "  - Veiller à une expérience utilisateur fluide avec des messages d’erreur explicites.\n",
    "  - Effectuer des tests sur différents navigateurs pour assurer la compatibilité.\n",
    "  - Implémenter une fonctionnalité de feedback utilisateur pour améliorer le système.\n",
    "\n",
    "- **Suivi en production :**\n",
    "  - Configurer les logs détaillés via Azure Application Insight pour identifier les erreurs.\n",
    "  - Mettre en place des seuils d'alerte pour détecter les dérives de performance.\n",
    "  - Définir un processus d’amélioration continue basé sur l'analyse des métriques de production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\" color: black; font-weight: bold; background-color: #f9e79f; padding: 10px; border-radius: 5px;\">\n",
    "    Notions clés :\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Le Deep Learning :** \n",
    "  Le deep learning, ou apprentissage profond, est une branche du machine learning qui repose sur des réseaux de neurones artificiels. Ces réseaux sont constitués de plusieurs couches successives de neurones, chacune ayant pour rôle de détecter des motifs de plus en plus complexes dans les données. Inspiré du fonctionnement du cerveau humain, le deep learning est particulièrement efficace pour traiter des données massives et non structurées telles que les images, le texte ou l’audio. Son succès repose en grande partie sur la disponibilité de grandes quantités de données et la puissance de calcul accrue des processeurs modernes, en particulier les GPU. Dans notre projet, nous utiliserons le deep learning pour comprendre et analyser le sentiment des tweets.\n",
    "\n",
    "- **API (Application Programming Interface) :** \n",
    "  Une API est une interface qui permet à des applications différentes de communiquer entre elles de manière standardisée. Elle définit un ensemble de règles et de conventions permettant à un logiciel d'offrir ses fonctionnalités à d'autres programmes sans que ceux-ci n'aient besoin de connaître les détails internes de son fonctionnement. Par exemple, une API de prédiction de sentiment prend en entrée un tweet et renvoie en sortie le sentiment associé (positif ou négatif). L'API facilite ainsi l’intégration du modèle d’analyse de sentiments dans divers systèmes, tels que des applications web ou mobiles.\n",
    "\n",
    "- **MLFlow :** \n",
    "  MLFlow est une plateforme open-source dédiée à la gestion du cycle de vie des projets de machine learning. Elle offre plusieurs fonctionnalités essentielles, notamment le suivi des expérimentations, la gestion des modèles et leur déploiement. Grâce à MLFlow, les data scientists peuvent enregistrer les hyperparamètres, suivre les métriques de performance et conserver une trace des versions du modèle pour assurer la reproductibilité et la traçabilité. Dans notre projet, MLFlow sera utilisé pour consigner les différentes itérations de nos modèles et faciliter leur comparaison.\n",
    "\n",
    "- **Streamlit :** \n",
    "  Streamlit est un outil simple et puissant qui permet de créer des applications web interactives pour afficher et manipuler des données de machine learning. Il permet aux data scientists et ingénieurs de déployer rapidement des interfaces graphiques sans avoir besoin de compétences avancées en développement web. Grâce à Streamlit, il est possible de saisir des tweets en temps réel, d'afficher les prédictions du modèle et d’offrir une expérience utilisateur fluide et intuitive.\n",
    "\n",
    "- **La démarche MLOps :**\n",
    "  MLOps (Machine Learning Operations) est une discipline qui vise à intégrer les principes du DevOps dans le cycle de vie des modèles de machine learning. Il s’agit d’automatiser et d’optimiser chaque étape du développement, du déploiement et de la maintenance des modèles afin d'assurer leur efficacité à long terme. \n",
    "  - **Principes fondamentaux de MLOps :**\n",
    "    - Automatisation des tâches répétitives telles que le prétraitement des données, l'entraînement et l'évaluation des modèles.\n",
    "    - Collaboration entre les équipes de data science, développement et opérations.\n",
    "    - Suivi continu et amélioration des performances du modèle en production.\n",
    "  - **Étapes pouvant être mises en œuvre dans notre projet :**\n",
    "    1. **Tracking des expérimentations :** Enregistrement des métriques et des résultats avec MLFlow.\n",
    "    2. **Stockage et gestion des versions :** Archivage des différents modèles pour garantir la reproductibilité.\n",
    "    3. **Déploiement :** Mise en place d'un pipeline CI/CD pour automatiser le passage en production.\n",
    "    4. **Suivi en production :** Surveillance des performances en temps réel via Azure Application Insights.\n",
    "    5. **Amélioration continue :** Analyse des prédictions erronées pour affiner le modèle au fil du temps.\n",
    "\n",
    "- **CI/CD (Continuous Integration/Continuous Deployment) :**\n",
    "  Le CI/CD est une approche d'automatisation du développement logiciel visant à assurer une intégration continue (CI) des modifications du code et un déploiement continu (CD) des mises à jour. Cela permet d'éviter les erreurs humaines et d'accélérer le cycle de mise en production grâce à des outils comme GitHub Actions ou Jenkins.\n",
    "\n",
    "- **Métriques de performance :**\n",
    "  Pour évaluer la performance des modèles, plusieurs métriques peuvent être utilisées, telles que :\n",
    "  - **Accuracy** (précision globale des prédictions),\n",
    "  - **F1-score** (harmonisation de la précision et du rappel),\n",
    "  - **ROC-AUC** (capacité du modèle à distinguer les classes),\n",
    "  - **Recall/Precision**, pour évaluer les faux positifs et faux négatifs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\" color: black; font-weight: bold; background-color: #f9e79f; padding: 10px; border-radius: 5px;\">\n",
    "    Création de l'environnement Python pour Jupyter Notebook sous VSCode :\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour utiliser un Jupyter Notebook avec VSCode, il est essentiel de configurer un environnement Python propre au projet. Voici les étapes recommandées :\n",
    "\n",
    "1. **Création d'un environnement virtuel spécifique au projet :**\n",
    "   ```bash\n",
    "   python -m venv sentiment_env\n",
    "   source sentiment_env/bin/activate  # Sur macOS/Linux\n",
    "   sentiment_env\\Scripts\\activate    # Sur Windows\n",
    "   ```\n",
    "\n",
    "2. **Installation des dépendances nécessaires :**\n",
    "   Après activation de l'environnement virtuel, installez les bibliothèques requises pour le projet :\n",
    "   ```bash\n",
    "   pip install --upgrade pip\n",
    "   pip install jupyter numpy pandas scikit-learn tensorflow keras matplotlib seaborn mlflow streamlit\n",
    "   ```\n",
    "\n",
    "3. **Gestion des dépendances :**\n",
    "   Pour assurer la portabilité du projet, exportez la liste des packages installés :\n",
    "   ```bash\n",
    "   pip freeze > requirements.txt\n",
    "   ```\n",
    "   Cette liste pourra être utilisée pour recréer l'environnement sur une autre machine :\n",
    "   ```bash\n",
    "   pip install -r requirements_base.txt\n",
    "   ```\n",
    "\n",
    "En suivant ces étapes, vous disposerez d'un environnement Python propre et reproductible, facilitant le développement et l'expérimentation dans Jupyter Notebook via VSCode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ce document constitue une introduction méthodologique et une analyse des exigences du projet. \n",
    "Il vise à clarifier les objectifs, la problématique et la méthodologie avant la réalisation effective des livrables.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
