import pytest
import requests
import logging

# ==============================
# ğŸ“Œ Configuration des tests
# ==============================
API_URL = "http://localhost:8000"

# Activation des logs
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# ==============================
# ğŸ“Œ VÃ©rification si l'API est bien en ligne
# ==============================
@pytest.fixture(scope="session", autouse=True)
def check_api_running():
    """VÃ©rifie si l'API est bien en ligne avant d'exÃ©cuter les tests."""
    try:
        response = requests.get(f"{API_URL}/health", timeout=5)
        assert response.status_code == 200, "âŒ L'API ne rÃ©pond pas !"
        logging.info("âœ… API accessible, dÃ©but des tests...")
    except requests.exceptions.RequestException as e:
        pytest.exit(f"âŒ Impossible de contacter l'API : {e}")

# ==============================
# ğŸ“Œ Test de l'endpoint /health
# ==============================
def test_health():
    """Teste si l'endpoint /health renvoie bien un statut OK."""
    response = requests.get(f"{API_URL}/health")
    assert response.status_code == 200
    data = response.json()

    assert data["status"] == "running", "âŒ L'API ne semble pas active."
    assert "model_loaded" in data, "âŒ ClÃ© 'model_loaded' absente de la rÃ©ponse."
    assert "tokenizer_loaded" in data, "âŒ ClÃ© 'tokenizer_loaded' absente de la rÃ©ponse."

    logging.info("âœ… Test /health : API en ligne et modÃ¨le chargÃ©")

# ==============================
# ğŸ“Œ Tests de prÃ©diction avec plusieurs tweets
# ==============================
@pytest.mark.parametrize("tweet", [
    ("J'adore ce produit, il est gÃ©nial!", "positif"),
    ("Ce service est terrible, je suis dÃ©Ã§u.", "nÃ©gatif"),
    ("C'est une belle journÃ©e ensoleillÃ©e.", None),  # Cas neutre possible
    ("Horrible expÃ©rience, je ne reviendrai plus !", "nÃ©gatif"),
    ("Fantastique ! Excellent service client !", "positif"),
])
def test_predict(tweet):
    """Teste la prÃ©diction d'un tweet."""
    response = requests.post(f"{API_URL}/predict", json={"tweet": tweet[0]})
    assert response.status_code == 200
    assert "sentiment" in response.json(), "âŒ ClÃ© 'sentiment' absente de la rÃ©ponse."
    sentiment = response.json()["sentiment"]

    if tweet[1]:  # VÃ©rifier si un sentiment attendu est dÃ©fini
        assert sentiment in ["positif", "nÃ©gatif"], f"âŒ Sentiment inattendu : {sentiment}"
    
    logging.info(f"âœ… Test prÃ©diction : '{tweet[0]}' â†’ {sentiment}")

# ==============================
# ğŸ“Œ Test d'entrÃ©e invalide (absence de champ 'tweet')
# ==============================
def test_predict_invalid_input():
    """Teste une requÃªte invalide sans champ 'tweet'."""
    response = requests.post(f"{API_URL}/predict", json={})  # JSON vide
    assert response.status_code == 422, "âŒ L'API aurait dÃ» renvoyer une erreur 422."
    logging.info("âœ… Test requÃªte invalide : erreur 422 bien renvoyÃ©e.")

# ==============================
# ğŸ“Œ Test de mise Ã  jour du modÃ¨le
# ==============================
def test_update_model():
    """Teste la mise Ã  jour du modÃ¨le via l'API."""
    response = requests.post(f"{API_URL}/update-model")
    assert response.status_code == 200
    assert response.json()["message"] == "âœ… ModÃ¨le '" + response.json().get("model_name", "") + "' mis Ã  jour avec succÃ¨s", "âŒ Message inattendu aprÃ¨s mise Ã  jour."
    logging.info("âœ… Test mise Ã  jour du modÃ¨le rÃ©ussi")

# ==============================
# ğŸ“Œ ExÃ©cution des tests
# ==============================
if __name__ == "__main__":
    pytest.main()
